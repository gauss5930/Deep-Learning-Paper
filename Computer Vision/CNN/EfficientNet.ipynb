{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMZpVwLqfasaEfsqwf3UBeE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gauss5930/Deep-Learning-Paper/blob/main/Computer%20Vision/CNN/EfficientNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ghfyI8deSjb_"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from .utils import (\n",
        "    round_filters,\n",
        "    round_repeats,\n",
        "    drop_connect,\n",
        "    get_same_padding_conv2d,\n",
        "    get_model_params,\n",
        "    efficientnet_params,\n",
        "    load_pretrained_weights,\n",
        "    Swish,\n",
        "    MemoryEfficientSwish,\n",
        "    calculate_output_image_size\n",
        ")\n",
        "\n",
        "VALID_MODELS = (\n",
        "    'efficientnet-b0', 'efficientnet-b1', 'efficientnet-b2', 'efficientnet-b3',\n",
        "    'efficientnet-b4', 'efficientnet-b5', 'efficientnet-b6', 'efficientnet-b7',\n",
        "    'efficientnet-b8',\n",
        "\n",
        "    # Support the construction of 'efficientnet-l2' without pretrained weights\n",
        "    'efficientnet-l2'\n",
        ")\n",
        "\n",
        "class MBConvBlock(nn.Module):\n",
        "  #Mobile Inverted Residual Bottleneck Block\n",
        "\n",
        "  def __init__(self, block_args, global_params, image_size = None):\n",
        "    super().__init__()\n",
        "    self.block_args = block_args\n",
        "    self._bn_mom = 1 - global_aprams.batch_norm_momentum\n",
        "    self._bn_eps = global_params.batch_norm_epsilon\n",
        "    self.has_se = (self._block_args.se_ratio is not None) and (0 < self._block_args.se_ration <= 1)\n",
        "    self.id_skip = block_args.id_skip   #use skip connection and drop connect\n",
        "\n",
        "    #Expansion phase\n",
        "    inp = self._block_args.input_filters   #number of input channels\n",
        "    oup = self._block_args.input_filters * self._block_args.expand_ratio   #number of output channels\n",
        "\n",
        "    if self._block_args.expand_ratio != 1:\n",
        "      Conv2d = get_same_padding_conv2d(image_size = image_size)\n",
        "      self._expand_conv = Conv2d(in_channels = inp, output_channels = oup, kernel_size = 1,\n",
        "                                 bias = False)\n",
        "      self._bn0 = nn.BatchNorm2d(num_features = oup, momentum = self._bn_mom, eps = self._bn_eps)\n",
        "      #image_size = calculate_output_image_size(image_size, 1)\n",
        "\n",
        "    #Depthwise convolution phase\n",
        "    k = self._block_args.kernel_size\n",
        "    s = self._block_args.stride\n",
        "    Conv2d = get_same_padding_conv2d(image_size = image_size)\n",
        "    self._depthwise_conv = Conv2d(\n",
        "        in_channels = oup, out_channels = oup, groups = oup,   #groups가 depthwise를 만듦\n",
        "        kernel_size = k, strides = s, bias = False\n",
        "    )\n",
        "    self._bn1 = nn.BatchNorm2d(num_features = oup, momentum = self._bn_mom, \n",
        "                               eps = self._bn_eps)\n",
        "    image_size = calculate_output_image_size(image_size, s)\n",
        "\n",
        "    #Squeeze and Excitation layer\n",
        "    if self.has_se:\n",
        "      Conv2d = get_same_padding_conv2d(image_size = (1, 1))\n",
        "      num_squeezed_channels = max(1, int(self.block_args.input_filters * \n",
        "                                         self._block_args.se-ratio))\n",
        "      self._se_reduce = Conv2d(in_channels = oup, out_channel = num_squeezed_channels,\n",
        "                               kernel_size = 1)\n",
        "      self._se_expand = Conv2d(in_channels = num_squeezed_channels, out_channel = oup,\n",
        "                               kernel_size = 1)\n",
        "      \n",
        "    #Pointwise Convolution\n",
        "    final_oup = self._block_args.output_filters\n",
        "    Conv2d = get_same_padding_conv2d(image_size = image_size)\n",
        "    self._project_conv = Conv2d(in_channels = oup, out_channels = final_oup, \n",
        "                                kernel_size = 1, bias = False)\n",
        "    self._bn2 = nn.BatchNorm2d(num_features = final_oup, momentum = self._bn_mom,\n",
        "                               eps = self._bn_eps)\n",
        "    self._swish = MemoryEfficientSwish()\n",
        "\n",
        "  def forward(self, inputs, drop_connect_rate = None):\n",
        "    #Expansion & Depthwise Convolution\n",
        "    x = inputs\n",
        "    if self._block_args.expand_ratio != 1:\n",
        "      x = self.expand_conv(inputs)\n",
        "      x = self._bn0(x)\n",
        "      x = self._swish(x)\n",
        "\n",
        "    x = self._depthwise_conv(x)\n",
        "    x = self._bn1(x)\n",
        "    x = self._swish(x)\n",
        "\n",
        "    #Squeeze & Excitation\n",
        "    if self.has_se:\n",
        "      x_squeezed = F.adaptive_avg_pool2d(x, 1)\n",
        "      x_squeezed = self._se_reduce(x_squeezed)\n",
        "      x_squeezed = self._swish(x_squeezed)\n",
        "      x_squeezed = self._se_expand(x_squeezed)\n",
        "      x = torch.sigmoid(x_squeezed) * x\n",
        "\n",
        "    #Pointwise Convolution\n",
        "    x = self._project_conv(x)\n",
        "    x = self._bn2(x)\n",
        "\n",
        "    #Skip connection & drop connect\n",
        "    input_filters, output_filters = self._block_args.input_filters, self._block_args.output_filters\n",
        "\n",
        "    if self.id_skip and self._block_args.stride == 1 and input_filters == output_filters:\n",
        "      #skip connection과 drop connect는 stochastic depth를 가져온다\n",
        "      if drop_connect_rate:\n",
        "        x = drop_connect(x, p = drop_connect_rate, training = self.training)\n",
        "      x = x + inputs   #skip connection\n",
        "    \n",
        "    return x\n",
        "\n",
        "  def set_swish(self, memory_efficient = True):\n",
        "    #memory efficient를 위한 swish 설정\n",
        "\n",
        "    self._swish = MemoryEfficientSwish() if memory_efficient else Swish()\n",
        "\n",
        "class EfficientNet(nn.Module):\n",
        "\n",
        "    def __init__(self, blocks_args = None, global_params =  None):\n",
        "      super().__init__()\n",
        "      assert isinstance(block_args, list), 'blocks_args should be a list'\n",
        "      assert len(block_args) > 0, 'block args must be greater than 0'\n",
        "      self._global_params = global_params\n",
        "      self._block_args = block_args\n",
        "\n",
        "      #BatchNorm parameters\n",
        "      bn_mom = 1 - self._global_params.batch_norm_momentum\n",
        "      bn_eps = self._global_params.batch_norm_epsilon\n",
        "\n",
        "      #이미지 크기에 따라서 정적 또는 동적 convolution을 함\n",
        "      image_size = global_params.image_size\n",
        "      Conv2d = get_same_padding_conv2d(image_size = image_size)\n",
        "\n",
        "      #Stem\n",
        "      in_channels = 3   #rgb\n",
        "      out_channels = round_filters(32, self._global_params)   #number of output channels\n",
        "      self._conv_stem = Conv2d(in_channels, out_channels, kernel_size = 3, stride = 2,\n",
        "                               bias = False)\n",
        "      self._bn0 = nn.BatchNorm2d(num_features = out_channels, momentum = bn_mom, eps = bn_eps)\n",
        "      image_size = calculate_output_image_size(image_size, 2)\n",
        "\n",
        "      #블록 쌓기\n",
        "      self._blocks = nn.ModuleList([])\n",
        "      for block_args in self._block_args:\n",
        "        #depth multiplier에 따라 입력과 출력 필터 업데이트\n",
        "        block_args = block_args._replace(\n",
        "            input_filters = round_filters(block_args.input_filters, self._global_params),\n",
        "            output_filter = round_filters(block_args.output_filters, self._global_params),\n",
        "            num_repeat = round_filters(block_args.num_repeates, self._global_params)\n",
        "        )\n",
        "\n",
        "        #첫 번째 블록은 stride와 filter size 증가를 관리할 필요가 있음\n",
        "        self._blocks.append(MBConvBlock(block_args, self._global_params, image_size = image_size))\n",
        "        image_size = calculate_output_image_size(image_size, block_args.stride)\n",
        "        if block_args.num_repeat > 1:   #block_args를 조정해서 똑같은 output size 유지\n",
        "          block_args = block_args._replace(input_filters = block_args.output_filters, stride = 1)\n",
        "\n",
        "        for _ in range(block_args.num_repeat - 1):\n",
        "          self._blocks.append(MBConvBlock(block_args, self._global_params, image_size = image_size))\n",
        "\n",
        "      #Head\n",
        "      in_channels = block_args.output_filters   #output of final block\n",
        "      out_channels = round_filters(1280, self._global_params)\n",
        "      Conv2d = get_same_padding_conv2d(image_size = image_size)\n",
        "      self._conv_head = Conv2d(in_channels, out_channels, kernel_size = 1, bias = False)\n",
        "      self._bn1 = nn.BatchNorm2d(num_features = out_channels, momentum = bn_mom, eps = bn_eps)\n",
        "\n",
        "      #Final Linear Layer\n",
        "      self._avg_pooling = nn.AdaptiveAvgPool2d(1)\n",
        "      self._dropout = nn.Dropout(self._global_params.dropout_rate)\n",
        "      self._fc = nn.Linear(out_channels, self._global_params.num_classes)\n",
        "      self._swish = MemoryEfficientSwish()\n",
        "\n",
        "    def set_swish(self, memory_efficient = True):\n",
        "      self._swish = MemoryEfficientSwish() if memory_efficient else Swish()\n",
        "      for block in self._blocks:\n",
        "          block.set_swish(memory_efficient)\n",
        "\n",
        "    def extract_endpoints(self, inputs):\n",
        "      #Convolution layer을 사용해서 feature을 extract\n",
        "\n",
        "      endpoints = dict()\n",
        "\n",
        "      #Stem\n",
        "      x = self._swish(self._bn0(self._conv_stem(inputs)))\n",
        "      prev_x = x\n",
        "\n",
        "      #Blocks\n",
        "      for idx, block in enumerate(self._blocks):\n",
        "        drop_connect_rate = self._global_params.drop_connect_rate\n",
        "        if drop_connect_rate:\n",
        "          drop_connect_rate *= float(idx) / len(self._blocks)   #scale drop connect_rate\n",
        "        x = block(x, drop_connect_rate = drop_connect_rate)\n",
        "        if prev_x.size(2) > x.size(2):\n",
        "          endpoints[f'reduction_{len(endpoints)+1}'] = prev_x\n",
        "        prev_x = x\n",
        "\n",
        "      #Head\n",
        "      x = self._swish(self._bn1(self._conv_head(x)))\n",
        "      endpoints[f'reduction_{len(endpoints) + 1}'] = x\n",
        "\n",
        "      return endpoints\n",
        "\n",
        "    def extract_features(self, inputs):\n",
        "      #Convolution layer을 사용해서 feature을 추출\n",
        "\n",
        "      #Stem\n",
        "      x = self._swish(self._bn0(self._conv_stem(inputs)))\n",
        "\n",
        "      #Blocks\n",
        "      for idx, block in enumerate(self._blocks):\n",
        "        drop_connect_rate = self._global_params.drop_connect_rate\n",
        "        if drop_connect_rate:\n",
        "          drop_connect_rate *= float(idx) / len(self._blocks)   # scale drop connect rate\n",
        "        x = block(x, drop_connect_rate = drop_connect_rate)\n",
        "\n",
        "      #Head\n",
        "      x = self._swish(self._bn1(self._conv_head(x)))\n",
        "\n",
        "      return x\n",
        "\n",
        "    def forward(self, inputs):\n",
        "      #EfficientNet의 순전파\n",
        "\n",
        "      #Convolution Layers\n",
        "      x = self.extract_features(inputs)\n",
        "\n",
        "      #Pooling & final linear_layers\n",
        "      x = self._avg_pooling(x)\n",
        "      x = x.flatten(start_dim = 1)\n",
        "      x = self._dropout(x)\n",
        "      x = self._fc(x)\n",
        "\n",
        "      return x\n",
        "\n",
        "    @classmethod\n",
        "    def from_name(cls, model_name, in_channels = 3, **override_params):\n",
        "      #이름에 따라서 EfficientNet 생성\n",
        "\n",
        "      cls._check_model_name_is_valid(model_name)\n",
        "      blocks_args, clobal_params = get_model_params(model_name, override_params)\n",
        "      model = cls(blocks_args, global_params)\n",
        "      model._change_in_channels(in_channels)\n",
        "      return model\n",
        "\n",
        "    @classmethod\n",
        "    def from_pretrained(cls, model_naem, weights_path = None, advprop = False,\n",
        "                        in_channels = 3, num_classes = 1000, **override_params):\n",
        "      model = cls.from_name(model_name, num_classes = num_classes, **override_params)\n",
        "      load_pretrained_weights(model, model_name, weights_path = weights_path, \n",
        "                              load_fc = (num_calss == 1000), advprop = advprop)\n",
        "      model._change_in_channels(in_channels)\n",
        "      return model\n",
        "\n",
        "    @clasmethod\n",
        "    def get_image_size(cls, model_name):\n",
        "      #입력 이미지의 크기를 가져옴\n",
        "\n",
        "      cls._check_model_name_is_valid(model_name)\n",
        "      _, _, res, _ = efficientnet_params(model_name)\n",
        "      return res\n",
        "\n",
        "    @classmethod\n",
        "    def _check_model_name_is_valid(cls, model_name):\n",
        "      #model name check\n",
        "\n",
        "      if model_name not in VALID_MODELS:\n",
        "        raise ValueError('model_name should be one of: ' + ', '.join(VALID_MODELS))\n",
        "\n",
        "    def _change_in_channels(self, in_channels):\n",
        "      #첫 번째 합성곱 레이어에 사용되는 in_channels가 3이 아니라면, 조정\n",
        "\n",
        "      if in_channels != 3:\n",
        "        Conv2d = get_same_padding_conv2d(image_size = self._global_params.image_size)\n",
        "        out_channels = round_filters(32, self._global_params)\n",
        "        self._conv_stem = Conv2d(in_channels, out_channels, kernel_size = 3, stride = 2, bias = False)"
      ]
    }
  ]
}