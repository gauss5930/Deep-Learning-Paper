{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOnDX2S9zG8B6oYDzT8Z794",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gauss5930/Deep-Learning-Paper/blob/main/Computer%20Vision/CNN/Xception.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Xception 모델 설명\n",
        "#당시, ImageNet에 대해서 SoTA를 차지함\n",
        "#VGG16과 ResNet의 입력 이미지 크기(224x224)와 다르게 (299x299)를 사용함\n",
        "#전처리 방식도 다름(Inception V3와 동일)\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import os\n",
        "import warnings\n",
        "\n",
        "import keras\n",
        "from keras import layers\n",
        "from keras.models import Sequential\n",
        "from keras import backend\n",
        "#얘네는 오류 발생\n",
        "#from . import get_submodules_from_kwargs\n",
        "#from . import imagenet_utils\n",
        "#from .imagenet_utils import decode_predictions\n",
        "#from .imagenet_utils import _obtain_input_shape\n",
        "\n",
        "TF_WEIGHTS_PATH = (\n",
        "    'https://github.com/fchollet/deep-learning-models/'\n",
        "    'releases/download/v0.4/'\n",
        "    'xception_weights_tf_dim_ordering_tf_kernels.h5'\n",
        ")\n",
        "\n",
        "TF_WEIGHTS_PATH_NO_TOP = (\n",
        "    'https://github.com/fchollet/deep-learning-models/'\n",
        "    'releases/download/v0.4/'\n",
        "    'xception_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        ")\n",
        "\n",
        "def Xception(include_top = True, weights = 'imagenet', input_tensor = None, \n",
        "             input_shape = None, pooling = None, classes = 1000, **kwargs):\n",
        "  \n",
        "  #기본 입력 이미지의 크기는 299 x 299\n",
        "  #include_top: network의 맨 위에서 fc-layer을 포함할 지\n",
        "  #weights: 'None'은 무작위, 'imagenet'은 Imagenet에서 pre-training, 또는 업로드할 파일 경로\n",
        "  #input_tensor: 모델의 입력 이미지에 대해 사용할 추가적인 keras tensor\n",
        "  #input_shape: 옵션적 tuple 모양, 'include_top'이 False일 때만 사용 가능\n",
        "  #pooling: feature extraction을 위한 옵션적 pooling mode, 'include_top'이 False일 때만 사용 가능\n",
        "  #'None': 모델 출력이 4D tensor, 'avg': global average pooling이고 output은 2D tensor\n",
        "  #'max': global max pooling\n",
        "  #classes: 옵션적 class 수. 'include_top'이 True일 때와 'weights'가 명시되지 않았을 때 사용 가능\n",
        "\n",
        "  #weights에 아무런 값이 없을 때\n",
        "  if not (weights in {'imagenet', None} or os.path.exists(weights)):\n",
        "    raise ValueError('The `weights` argument should be either '\n",
        "                         '`None` (random initialization), `imagenet` '\n",
        "                         '(pre-training on ImageNet), '\n",
        "                         'or the path to the weights file to be loaded.')\n",
        "  \n",
        "  #imagenet을 weights로 사용하는데 조건이 맞지 않을 때\n",
        "  if weights == 'imagenet' and include_top and classes != 1000:\n",
        "    raise ValueError('If using `weights` as `\"imagenet\"` with `include_top`'\n",
        "                         ' as true, `classes` should be 1000')\n",
        "    \n",
        "  #적절한 입력 모양 결정\n",
        "  input_shape = _obtain_input_shape(input_shape, default_size = 299, min_size = 71,\n",
        "                                    data_format = backend.image_data_format(),\n",
        "                                    require_flatten = include_top, weights = weights)\n",
        "  \n",
        "  if input_tensor is None:\n",
        "    img_input = layers.Input(shape = input_shape)\n",
        "  else:\n",
        "    if not backend.is_keras_tensor(input_tensor):\n",
        "      img_input = layers.Input(tensor = input_tensor, shape = input_shape)\n",
        "    else:\n",
        "      img_input = input_tensor\n",
        "\n",
        "  channel_axis = 1 if backend.image_data_format() == 'channels_first' else -1\n",
        "\n",
        "  #Entry Flow\n",
        "  #입력 이미지 단계\n",
        "  x = layers.Conv2D(32, (3, 3), strides = (2, 2), use_bias = False,\n",
        "                    name = 'block1_conv1')(img_input)\n",
        "  x = layers.BatchNormalization(axis = channel_axis, name = 'block1_conv1_bn')(x)\n",
        "  x = layers.Activation('relu', name = 'block1_conv1_act')(x)\n",
        "  x = layers.Conv2D(64, (3, 3), use_bias = False, name = 'block1_conv2_bn')(x)\n",
        "  x = layers.Activation('relu', name = 'block1_conv2_act')(x)\n",
        "\n",
        "  #첫 번째 residual network\n",
        "  residual = layers.Conv2d(128, (1, 1), strides = (2, 2), padding = 'same', use_bias = False)(x)\n",
        "  residual = layers.BatchNormalization(axis = channel_axis)(residual)\n",
        "\n",
        "  x = layers.SeparableConv2D(128, (3, 3), padding = 'same', use_bias = False,\n",
        "                             name = 'block2_sepconv1')(x)\n",
        "  x = layers.BatchNormalization(axis = channel_axis, name = 'block2_sepconv1_bn')(x)\n",
        "  x = layers.Activation('relu', name = 'block2_sepconv2_act')(x)\n",
        "  x = layers.SeparableConv2D(128, (3, 3), padding = 'same', use_bias = 'same', \n",
        "                             name = 'block2_sepconv2')(x)\n",
        "  x = layers.BatchNormalization(axis = channel_axis, name = 'block2_sepconv2_bn')(x)\n",
        "\n",
        "  x = layers.MaxPooling2D((3, 3), strides = (2, 2), padding = 'same', \n",
        "                          name = 'block2_pool')(x)\n",
        "  x = layers.add([x, residual])\n",
        "\n",
        "  #두 번째 residual network\n",
        "  residual = layers.Conv2d(256, (1, 1), strides = (2, 2), padding = 'same', use_bias = False)(x)\n",
        "  residual = layers.BatchNormalization(sxis = channel_axis)(residual)\n",
        "\n",
        "  x = layers.Activation('relu', name = 'block3_conv1_act')(x)\n",
        "  x = layers.SeparableConv2D(256, (3, 3), strides = 'same', use_bias = False, \n",
        "                             name = 'block3_sepconv1')(x)\n",
        "  x = layers.BatchNormalization(axis = channel_axis, name = 'block3_sepconv1_bn')(x)\n",
        "\n",
        "  x = layers.Activation('relu', name = 'block3_conv2_act')(x)\n",
        "  x = layers.SeparableConv2D(256, (3, 3), strides = 'same', use_bias = False, \n",
        "                             name = 'block3_sepconv2')(x)\n",
        "  x = layers.BatchNormalization(axis = channel_axis, name = 'block3_sepconv2_bn')(x)\n",
        "\n",
        "  x = layers.MaxPooling2D((3, 3), strides = (2, 2), padding = 'same', \n",
        "                          name = 'block3_pool')(x)\n",
        "\n",
        "  x = layers.add([x, residual])\n",
        "\n",
        "  #세 번째 residual network\n",
        "  residual = layers.Conv2d(728, (1, 1), strides = (2, 2), padding = 'same', use_bias = False)(x)\n",
        "  residual = layers.BatchNormalization(axis = channel_axis)(residual)\n",
        "\n",
        "  x = layers.Activation('relu', name = 'block4_conv1_act')(x)\n",
        "  x = layers.SeparableConv2D(728, (3, 3), strides = 'same', use_bias = False, \n",
        "                             name = 'block4_sepconv1')(x)\n",
        "  x = layers.BatchNormalization(axis = channel_axis, name = 'block4_sepconv1_bn')(x)\n",
        "\n",
        "  x = layer.Activation('relu', name = 'block4_conv2_act')(x)\n",
        "  x = layers.SeparableConv2D(728, (3, 3), strides = 'same', use_bias = False,\n",
        "                             name = 'block4_sepconv2')(x)\n",
        "  x = layers.BatchNormalization(axis = channel_axis, name = 'block4_sepconv2_bn')(x)\n",
        "  \n",
        "  x = MaxPooling2D((3, 3), strides = (2, 2), padding = 'same', name = 'block4_pool')(x)\n",
        "\n",
        "  x = layers.add([x, residual])\n",
        "\n",
        "  #Middle Flow\n",
        "  for i in range(8):\n",
        "    residual = x\n",
        "    prefix = 'block' + str(i + 5)   #블록 이름 지정 자동화\n",
        "    \n",
        "    x = layers.Activation('relu', name = prefix + '_sepconv1_act')(x)\n",
        "    x = layers.SeparableConv2D(728, (3, 3), strides = 'same', use_bias = False, \n",
        "                               name = prefix + '_sepconv1')(x)\n",
        "    x = layers.BatchNormalization(axis = channel_axis, name = prefix + '_sepconv1_bn')(x)\n",
        "\n",
        "    x = layers.Activation('relu', name = prefix + '_sepconv2_act')(x)\n",
        "    x = layers.SeparableConv2D(728, (3, 3), strides = 'same', use_bias = False, \n",
        "                               name = prefix + '_sepconv2')(x)\n",
        "    x = layers.BatchNormalization(axis = channel_axis, name = prefix + '_sepconv2_bn')(x)\n",
        "\n",
        "    x = layers.Activation('relu', name = prefix + '_sepconv3_act')(x)\n",
        "    x = layers.SeparableConv2D(728, (3, 3), strides = 'same', use_bias = False, \n",
        "                               name = prefix + '_sepconv3')(x)\n",
        "    x = layers.BatchNormalization(axis = channel_axis, name = prefix + '_sepconv3_bn')(x)\n",
        "\n",
        "    x = layers.add([x, residual])\n",
        "\n",
        "  #Exit Flow\n",
        "  residual = layers.Conv2d(1024, (1, 1), strides = (2, 2), padding = 'same', use_bias = False)(x)\n",
        "  residual = layers.BatchNormalization(axis = channel_axis)(residual)\n",
        "\n",
        "  x = layers.Activation('relu', name = 'block13_sepconv1_act')(x)\n",
        "  x = layers.SeparableConv2D(728, (3, 3), strides = 'same', use_bias = False, \n",
        "                             name = 'block13_sepconv1')(x)\n",
        "  x = layers.BatchNormalization(axis = channel_axis, name = 'block13_sepconv1_bn')(x)\n",
        "\n",
        "  x = layers.Activation('relu', name = 'block13_speconv2_act')(x)\n",
        "  x = layers.SeparableConv2D(1024, (3, 3), strides = 'same', use_bias = False, \n",
        "                             name = 'block13_sepconv2')(x)\n",
        "  x = layers.BatchNormalization(axis = channel_axis, name = 'block13_sepconv2_bn')(x)\n",
        "\n",
        "  x = layers.MaxPooling2D((3, 3), strides = (2, 2), padding = 'same', name = 'block13_pool')(x)\n",
        "\n",
        "  x = layers.add([x, residual])\n",
        "\n",
        "  x = layers.SeparableConv2D(1536, (3, 3), strides = 'same', use_biad = False,\n",
        "                             name = 'block14_sepconv1')(x)\n",
        "  x = layers.BatchNormalization(axis = channel_axis, name = 'block14_sepconv1_bn')(x)\n",
        "  x = layers.Activation('relu', name = 'block14_sepconv_act')(x)\n",
        "\n",
        "  x = layers.SeparableConv2D(2048, (3, 3), strides = 'same', use_bias = False,\n",
        "                             name = 'block14_sepconv2')(x)\n",
        "  x = layers.BatchNormalization(axis = channel_axis, name = 'block14_speconv2_bn')(x)\n",
        "  x = layers.Activation('relu', name = 'block14_sepconv2_act')(x)\n",
        "\n",
        "  if include_top:\n",
        "    x = layers.GlobalAveragePooling2D(name = 'avg_pool')(x)\n",
        "    x = layers.Dense(classes, activation = 'softmax', name = 'predictions')(x)\n",
        "  else:\n",
        "    if pooling == 'avg':\n",
        "      x = layers.GlobalAveragePooling2D()(x)\n",
        "    elif pooling == 'max':\n",
        "      x = layers.MaxPooling2D()(x)\n",
        "\n",
        "  if input_tensor is not None:\n",
        "    inputs = keras_utils.get_source_inputs(input_tensor)\n",
        "  else:\n",
        "    inputs = img_input\n",
        "\n",
        "  #모델 생성\n",
        "  if weights == 'imagenet':\n",
        "    if include_top:\n",
        "      weights_path = keras_utils.get_file(\n",
        "          'xception_weights_tf_dim_ordering_tf_kernels.h5',\n",
        "          TF_WEIGHTS_PATH,\n",
        "          cache_subdir='models',\n",
        "          file_hash='0a58e3b7378bc2990ea3b43d5981f1f6'\n",
        "      )\n",
        "    else:\n",
        "      weights_path = keras_utils.get_file(\n",
        "          'xception_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
        "          TF_WEIGHTS_PATH_NO_TOP,\n",
        "          cache_subdir='models',\n",
        "          file_hash='b0042744bf5b25fce3cb969f33bebb97'\n",
        "      )\n",
        "    model.load_weights(weights_path)\n",
        "    if backend.backend() == 'theano':\n",
        "      keras_utils.convert_all_kernels_in_model(model)\n",
        "  elif weights is not None:\n",
        "    model.load_weights(weights)\n",
        "\n",
        "  return model\n",
        "\n",
        "def preprocess_input(x, **kwargs):\n",
        "  #Numpy 배열을 이미지 배치로 전처리\n",
        "  return imagenet_utils.preprocess_input(x, mode = 'tf', **kwargs)"
      ],
      "metadata": {
        "id": "2OJ6-sJPoqxo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}