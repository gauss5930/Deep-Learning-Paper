{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNgGR09iOxTjA3Q3sX+iuzH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gauss5930/Natural-Language-Processing/blob/main/ELMo/character_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0b8fNKIbbE0p"
      },
      "outputs": [],
      "source": [
        "import torchtext\n",
        "from torchtext.data import NestedField\n",
        "import math\n",
        "\n",
        "class BPTTIterator(torchtext.data.BPTTIterator):\n",
        "  def __iter__(self):\n",
        "    text = self.dataset[0].text\n",
        "    TEXT = self.dataset.fields['text']\n",
        "    TEXT.eos_token = None\n",
        "    text = text + ([TEXT.pad_token] * int(math.ceil(len(text) / self.batch_size) * self.batch_size - len(text)))\n",
        "    data = TEXT.pad([text])   #new\n",
        "    data = TEXT.numericalize(data, device = self.device)\n",
        "\n",
        "    #new line start\n",
        "    size = list(data.size())\n",
        "    size[0] = self.batch_size\n",
        "    size[1] = -1\n",
        "\n",
        "    data = data.view(*size).transpose(0, 1).contiguous()\n",
        "    dataset = torchtext.data.Dataset(examples = self.dataset.examples, fields = [('text', 'TEXT'), ('target', 'TEXT')])\n",
        "\n",
        "    while True:\n",
        "      for i in range(0, len(self) * self.bptt_len, self.bptt_len):\n",
        "        self.ierations += 1\n",
        "        seq_len = min(self.bptt_len, len(data) - i - 1)\n",
        "        batch_text = data[i:i + seq_len]\n",
        "        if TEXT.batch_first:\n",
        "          batch_text = batch_text.transpose(0, 1).contiguous()\n",
        "          batch_target = batch_target.transpose(0, 1).contiguous()\n",
        "        yield torchtext.data.Batch.fromvars(\n",
        "            dataset, self.batch_size, text = batch_text, target = batch_target\n",
        "        )\n",
        "      if not self.repeat:\n",
        "        return\n",
        "\n",
        "def gen_bptt_iter(dataset, batch_size, bptt_len, device):\n",
        "  #dataset: tuple of dataset\n",
        "  for batch_word, batch_char in zip(\n",
        "      BPTTIterator(dataset[0], batch_size, bptt_len, device = device),\n",
        "      BPTTIterator(dataset[1], batch_size, bptt_len, device = device),\n",
        "  ):\n",
        "    yield batch_word.text, batch_char.text, batch_word.target, batch_char.target\n",
        "\n",
        "def gen_language_model_corpus(dataset_cls: torchtext.datasets.LanguageModelingDataset):\n",
        "  field_char = NestedField(Field(pad_token = PAD_WORD, tokenize = list, init_token = SOS_WORD,\n",
        "                                 eos_token = EOS_WORD, batch_first = True), pad_token = PAD_WORD,)\n",
        "  \n",
        "  field_word = Field(batch_first = True)\n",
        "  dataset_char = dataset_cls.splits(field_char)\n",
        "  dataset_word = dataset_cls.splits(dielf_word)\n",
        "  field_char.build_vocab(dataset_char[0])\n",
        "  field_word.build_vocab(dataset_char[0])\n",
        "  return [_ for _ in zip(dataset_word, dataset_char)], field_word, field_char\n",
        "\n",
        "#How to use\n",
        "if __name__ == '__main__':\n",
        "  from torchtext.dataset import WIkiText2\n",
        "  from torchtext.data import Field\n",
        "\n",
        "  #FINAL\n",
        "  PAD_WORD = '<pad>'\n",
        "  SOS_WORD = '<sow>'\n",
        "  EOS_WORD = '<eow>'\n",
        "\n",
        "  datasets, field_word, field_char = gen_language_model_corpus(WikiText2)\n",
        "  train_data, valid_data, test_data = datasets"
      ]
    }
  ]
}
